{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3152 rows\n",
      "21574 rows\n",
      "21574 16180 5394\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spn.algorithms.Inference import log_likelihood\n",
    "from spn.algorithms.LearningWrappers import learn_parametric\n",
    "from spn.structure.Base import Context\n",
    "from spn.structure.leaves.parametric.Parametric import Categorical, Gaussian, Bernoulli\n",
    "import numpy as np\n",
    "\n",
    "newnames = ['telephoning',\n",
    " 'medicine',\n",
    " 'money',\n",
    " 'traveling',\n",
    " 'outside',\n",
    " 'grocery',\n",
    " 'cooking',\n",
    " 'laundry',\n",
    " 'light',\n",
    " 'heavy',\n",
    " 'toilet',\n",
    " 'bathing',\n",
    " 'dressing',\n",
    " 'inside',\n",
    " 'bed',\n",
    " 'eating']\n",
    "\n",
    "frame = pd.read_csv(\"nltcs/2to16disabilityNLTCS.txt\", sep='\\t').drop(['PERCENT'], axis=1)\n",
    "frame = frame.rename({old: new  for old, new in zip(frame.columns, newnames)}, axis=1)\n",
    "print (\"%d rows\" % len(frame))\n",
    "\n",
    "D = frame.to_numpy()\n",
    "expanded = []\n",
    "for row in D:\n",
    "    expanded.append([list(row[0:-1])] * row[-1])\n",
    "D = np.concatenate(expanded, axis=0)\n",
    "frame = pd.DataFrame(D, columns = frame.columns[:-1])\n",
    "print (\"%d rows\" % len(frame))\n",
    "train, test = train_test_split(frame, random_state = 0)\n",
    "print (len(frame), len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(heavy)</td>\n",
       "      <td>(outside)</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.552596</td>\n",
       "      <td>0.473177</td>\n",
       "      <td>0.700586</td>\n",
       "      <td>1.267809</td>\n",
       "      <td>0.099953</td>\n",
       "      <td>1.494264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(outside)</td>\n",
       "      <td>(heavy)</td>\n",
       "      <td>0.552596</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.473177</td>\n",
       "      <td>0.856280</td>\n",
       "      <td>1.267809</td>\n",
       "      <td>0.099953</td>\n",
       "      <td>2.258547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(traveling)</td>\n",
       "      <td>(outside)</td>\n",
       "      <td>0.493634</td>\n",
       "      <td>0.552596</td>\n",
       "      <td>0.386341</td>\n",
       "      <td>0.782647</td>\n",
       "      <td>1.416310</td>\n",
       "      <td>0.113561</td>\n",
       "      <td>2.058420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(traveling)</td>\n",
       "      <td>(heavy)</td>\n",
       "      <td>0.493634</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.436156</td>\n",
       "      <td>0.883561</td>\n",
       "      <td>1.308200</td>\n",
       "      <td>0.102754</td>\n",
       "      <td>2.787706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(traveling, heavy)</td>\n",
       "      <td>(outside)</td>\n",
       "      <td>0.436156</td>\n",
       "      <td>0.552596</td>\n",
       "      <td>0.356613</td>\n",
       "      <td>0.817628</td>\n",
       "      <td>1.479613</td>\n",
       "      <td>0.115595</td>\n",
       "      <td>2.453249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>(laundry)</td>\n",
       "      <td>(traveling, grocery, heavy)</td>\n",
       "      <td>0.353585</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>0.257355</td>\n",
       "      <td>0.727845</td>\n",
       "      <td>1.997376</td>\n",
       "      <td>0.128508</td>\n",
       "      <td>2.335430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>(laundry, bathing)</td>\n",
       "      <td>(heavy)</td>\n",
       "      <td>0.261743</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.259394</td>\n",
       "      <td>0.991027</td>\n",
       "      <td>1.467315</td>\n",
       "      <td>0.082613</td>\n",
       "      <td>36.175623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>(laundry, heavy)</td>\n",
       "      <td>(bathing)</td>\n",
       "      <td>0.345179</td>\n",
       "      <td>0.440791</td>\n",
       "      <td>0.259394</td>\n",
       "      <td>0.751477</td>\n",
       "      <td>1.704837</td>\n",
       "      <td>0.107242</td>\n",
       "      <td>2.250131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>(laundry)</td>\n",
       "      <td>(bathing, heavy)</td>\n",
       "      <td>0.353585</td>\n",
       "      <td>0.394129</td>\n",
       "      <td>0.259394</td>\n",
       "      <td>0.733613</td>\n",
       "      <td>1.861355</td>\n",
       "      <td>0.120036</td>\n",
       "      <td>2.274403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>(cooking)</td>\n",
       "      <td>(heavy)</td>\n",
       "      <td>0.260321</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.254017</td>\n",
       "      <td>0.975783</td>\n",
       "      <td>1.444745</td>\n",
       "      <td>0.078196</td>\n",
       "      <td>13.403999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            antecedents                  consequents  antecedent support  \\\n",
       "0               (heavy)                    (outside)            0.675402   \n",
       "1             (outside)                      (heavy)            0.552596   \n",
       "2           (traveling)                    (outside)            0.493634   \n",
       "3           (traveling)                      (heavy)            0.493634   \n",
       "4    (traveling, heavy)                    (outside)            0.436156   \n",
       "..                  ...                          ...                 ...   \n",
       "160           (laundry)  (traveling, grocery, heavy)            0.353585   \n",
       "161  (laundry, bathing)                      (heavy)            0.261743   \n",
       "162    (laundry, heavy)                    (bathing)            0.345179   \n",
       "163           (laundry)             (bathing, heavy)            0.353585   \n",
       "164           (cooking)                      (heavy)            0.260321   \n",
       "\n",
       "     consequent support   support  confidence      lift  leverage  conviction  \n",
       "0              0.552596  0.473177    0.700586  1.267809  0.099953    1.494264  \n",
       "1              0.675402  0.473177    0.856280  1.267809  0.099953    2.258547  \n",
       "2              0.552596  0.386341    0.782647  1.416310  0.113561    2.058420  \n",
       "3              0.675402  0.436156    0.883561  1.308200  0.102754    2.787706  \n",
       "4              0.552596  0.356613    0.817628  1.479613  0.115595    2.453249  \n",
       "..                  ...       ...         ...       ...       ...         ...  \n",
       "160            0.364400  0.257355    0.727845  1.997376  0.128508    2.335430  \n",
       "161            0.675402  0.259394    0.991027  1.467315  0.082613   36.175623  \n",
       "162            0.440791  0.259394    0.751477  1.704837  0.107242    2.250131  \n",
       "163            0.394129  0.259394    0.733613  1.861355  0.120036    2.274403  \n",
       "164            0.675402  0.254017    0.975783  1.444745  0.078196   13.403999  \n",
       "\n",
       "[165 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, fpmax, fpgrowth, association_rules\n",
    "\n",
    "\n",
    "frequent_itemsets = fpgrowth(train, use_colnames=True, min_support = 0.25)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold = 0.7)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test condidence = 0.83, alen = 1.96, clen = 1.28\n"
     ]
    }
   ],
   "source": [
    "confidences = []\n",
    "for i, row in rules.iterrows():\n",
    "    acondition = None\n",
    "    for name in row.antecedents:\n",
    "        if acondition is None:\n",
    "            acondition = (test[name] == 1)\n",
    "        else:\n",
    "            acondition = acondition & (test[name] == 1)\n",
    "    \n",
    "    ccondition = None\n",
    "    for name in row.consequents:\n",
    "        if ccondition is None:\n",
    "            ccondition = (test[name] == 1)\n",
    "        else:\n",
    "            ccondition = ccondition & (test[name] == 1)\n",
    "    \n",
    "    confidences.append (len(test[acondition & ccondition]) / len(test[acondition]))\n",
    "\n",
    "print (\"test condidence = %.2f, alen = %.2f, clen = %.2f\" % (np.mean(confidences), \n",
    "                                                            rules.antecedents.apply(len).mean(), \n",
    "                                                            rules.consequents.apply(len).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
